"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[135],{8453(n,e,i){i.d(e,{R:()=>a,x:()=>s});var t=i(6540);const o={},r=t.createContext(o);function a(n){const e=t.useContext(r);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:a(n.components),t.createElement(r.Provider,{value:e},n.children)}},8823(n,e,i){i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>m,frontMatter:()=>a,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"chapters/module-3-simulation/chapter-12-isaac-sim-fundamentals","title":"Chapter 12 - NVIDIA Isaac Sim Fundamentals","description":"NVIDIA Isaac Sim fundamentals for high-fidelity humanoid robot simulation","source":"@site/docs/chapters/module-3-simulation/chapter-12-isaac-sim-fundamentals.md","sourceDirName":"chapters/module-3-simulation","slug":"/chapters/module-3-simulation/chapter-12-isaac-sim-fundamentals","permalink":"/docs/chapters/module-3-simulation/chapter-12-isaac-sim-fundamentals","draft":false,"unlisted":false,"editUrl":"https://github.com/RIMZAASAD/Robotic-ai-Book/edit/main/website/docs/chapters/module-3-simulation/chapter-12-isaac-sim-fundamentals.md","tags":[],"version":"current","frontMatter":{"title":"Chapter 12 - NVIDIA Isaac Sim Fundamentals","module":"Digital Twin Simulation","chapter":12,"description":"NVIDIA Isaac Sim fundamentals for high-fidelity humanoid robot simulation","learningObjectives":["Install and configure NVIDIA Isaac Sim for humanoid robotics","Create high-fidelity simulation environments","Implement physics and sensor simulation for humanoid robots"],"prerequisites":["chapter-11-unity-hri"],"difficulty":"advanced"},"sidebar":"textbookSidebar","previous":{"title":"Chapter 11: Unity for Human-Robot Interaction","permalink":"/docs/chapters/module-3-simulation/chapter-11-unity-hri"},"next":{"title":"Chapter 13: Isaac SDK for Perception & Synthetic Data","permalink":"/docs/chapters/module-3-simulation/chapter-13-isaac-sdk"}}');var o=i(4848),r=i(8453);const a={title:"Chapter 12 - NVIDIA Isaac Sim Fundamentals",module:"Digital Twin Simulation",chapter:12,description:"NVIDIA Isaac Sim fundamentals for high-fidelity humanoid robot simulation",learningObjectives:["Install and configure NVIDIA Isaac Sim for humanoid robotics","Create high-fidelity simulation environments","Implement physics and sensor simulation for humanoid robots"],prerequisites:["chapter-11-unity-hri"],difficulty:"advanced"},s=void 0,l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction",id:"introduction",level:2},{value:"Isaac Sim Overview",id:"isaac-sim-overview",level:2},{value:"Key Features and Capabilities",id:"key-features-and-capabilities",level:3},{value:"PhysX Physics Engine",id:"physx-physics-engine",level:4},{value:"RTX Rendering",id:"rtx-rendering",level:4},{value:"Omniverse Integration",id:"omniverse-integration",level:4},{value:"Architecture and Components",id:"architecture-and-components",level:3},{value:"Installing and Configuring Isaac Sim",id:"installing-and-configuring-isaac-sim",level:2},{value:"System Requirements",id:"system-requirements",level:3},{value:"Installation Methods",id:"installation-methods",level:3},{value:"Method 1: Omniverse Launcher (Recommended)",id:"method-1-omniverse-launcher-recommended",level:4},{value:"Method 2: Docker Container (Production)",id:"method-2-docker-container-production",level:4},{value:"Method 3: Standalone Installation",id:"method-3-standalone-installation",level:4},{value:"Initial Configuration",id:"initial-configuration",level:3},{value:"Essential Extensions for Humanoid Robotics",id:"essential-extensions-for-humanoid-robotics",level:3},{value:"Creating High-Fidelity Humanoid Environments",id:"creating-high-fidelity-humanoid-environments",level:2},{value:"USD Scene Structure",id:"usd-scene-structure",level:3},{value:"Basic Scene Setup",id:"basic-scene-setup",level:3},{value:"Physics Configuration for Humanoid Simulation",id:"physics-configuration-for-humanoid-simulation",level:3},{value:"Importing and Configuring Humanoid Robots",id:"importing-and-configuring-humanoid-robots",level:2},{value:"Using the URDF Importer",id:"using-the-urdf-importer",level:3},{value:"Physics Joints Configuration",id:"physics-joints-configuration",level:3},{value:"Advanced Sensor Simulation",id:"advanced-sensor-simulation",level:2},{value:"Camera Simulation for Vision Systems",id:"camera-simulation-for-vision-systems",level:3},{value:"IMU Simulation for Balance Feedback",id:"imu-simulation-for-balance-feedback",level:3},{value:"Force/Torque Sensors for Manipulation",id:"forcetorque-sensors-for-manipulation",level:3},{value:"ROS 2 Integration",id:"ros-2-integration",level:2},{value:"Setting up ROS Bridge",id:"setting-up-ros-bridge",level:3},{value:"High-Fidelity Physics Simulation",id:"high-fidelity-physics-simulation",level:2},{value:"Advanced PhysX Configuration",id:"advanced-physx-configuration",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Simulation Optimization Techniques",id:"simulation-optimization-techniques",level:3},{value:"Constitution Alignment",id:"constitution-alignment",level:2},{value:"Sim-to-Real Rigor (Principle III)",id:"sim-to-real-rigor-principle-iii",level:3},{value:"Real-Time Validation (Principle IV)",id:"real-time-validation-principle-iv",level:3},{value:"Target Hardware Optimization",id:"target-hardware-optimization",level:3},{value:"Visualization Requirements (Key Standard II)",id:"visualization-requirements-key-standard-ii",level:3},{value:"Practical Examples",id:"practical-examples",level:2},{value:"Example 1: Humanoid Balance Testing Environment",id:"example-1-humanoid-balance-testing-environment",level:3},{value:"Example 2: Manipulation Training Environment",id:"example-2-manipulation-training-environment",level:3},{value:"Exercises",id:"exercises",level:2},{value:"Exercise 1: Physics Configuration",id:"exercise-1-physics-configuration",level:3},{value:"Exercise 2: Sensor Integration",id:"exercise-2-sensor-integration",level:3},{value:"Exercise 3: Environment Creation",id:"exercise-3-environment-creation",level:3},{value:"Summary",id:"summary",level:2},{value:"Further Reading",id:"further-reading",level:2}];function d(n){const e={code:"code",h2:"h2",h3:"h3",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Install and configure NVIDIA Isaac Sim for humanoid robotics"}),"\n",(0,o.jsx)(e.li,{children:"Create high-fidelity simulation environments"}),"\n",(0,o.jsx)(e.li,{children:"Implement physics and sensor simulation for humanoid robots"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"introduction",children:"Introduction"}),"\n",(0,o.jsx)(e.p,{children:'NVIDIA Isaac Sim represents the state-of-the-art in high-fidelity robotics simulation, specifically designed to support the "Sim-to-Real Rigor" principle from our project constitution. Built on NVIDIA\'s Omniverse platform, Isaac Sim provides photorealistic rendering, accurate physics simulation, and comprehensive sensor modeling that enables effective training and validation of humanoid robots before deployment to physical hardware. This chapter covers the fundamentals of Isaac Sim, with special attention to its application in humanoid robotics, including the realistic physics simulation and sensor modeling required for the Vision-Language-Action pipeline.'}),"\n",(0,o.jsx)(e.h2,{id:"isaac-sim-overview",children:"Isaac Sim Overview"}),"\n",(0,o.jsx)(e.h3,{id:"key-features-and-capabilities",children:"Key Features and Capabilities"}),"\n",(0,o.jsx)(e.p,{children:"NVIDIA Isaac Sim provides several key capabilities that distinguish it from other simulation platforms:"}),"\n",(0,o.jsx)(e.h4,{id:"physx-physics-engine",children:"PhysX Physics Engine"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"High-fidelity physics"}),": Accurate simulation of rigid body dynamics, contacts, and constraints"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Multi-GPU support"}),": Leverages NVIDIA GPUs for accelerated physics computation"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Realistic contact modeling"}),": Advanced friction, restitution, and contact properties"]}),"\n"]}),"\n",(0,o.jsx)(e.h4,{id:"rtx-rendering",children:"RTX Rendering"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Photorealistic rendering"}),": RTX ray tracing for realistic lighting and materials"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Synthetic data generation"}),": High-quality training data for computer vision systems"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Sensor simulation"}),": Accurate camera, LIDAR, and other sensor models"]}),"\n"]}),"\n",(0,o.jsx)(e.h4,{id:"omniverse-integration",children:"Omniverse Integration"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"USD-based workflows"}),": Universal Scene Description for complex scene management"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Real-time collaboration"}),": Multiple users can work on the same simulation"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Extensible architecture"}),": Python API for custom extensions and behaviors"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"architecture-and-components",children:"Architecture and Components"}),"\n",(0,o.jsx)(e.p,{children:"Isaac Sim consists of several key components:"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Isaac Sim App"}),": The main simulation application"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Omniverse Kit"}),": Core platform for 3D simulation"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"PhysX Engine"}),": Physics simulation backend"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"RTX Renderer"}),": High-fidelity graphics rendering"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"ROS 2 Bridge"}),": Integration with Robot Operating System 2"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Extensions"}),": Modular components for specific functionality"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"installing-and-configuring-isaac-sim",children:"Installing and Configuring Isaac Sim"}),"\n",(0,o.jsx)(e.h3,{id:"system-requirements",children:"System Requirements"}),"\n",(0,o.jsx)(e.p,{children:"Before installing Isaac Sim, ensure your system meets the requirements:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"GPU"}),": NVIDIA RTX 4070 Ti (12GB) or higher (as specified in our constitution)"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"RAM"}),": 32GB or more recommended"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"OS"}),": Ubuntu 22.04 LTS (as specified in our constitution)"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"CUDA"}),": Compatible version for your GPU"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Docker"}),": For containerized deployment (optional but recommended)"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"installation-methods",children:"Installation Methods"}),"\n",(0,o.jsx)(e.h4,{id:"method-1-omniverse-launcher-recommended",children:"Method 1: Omniverse Launcher (Recommended)"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsx)(e.li,{children:"Download and install the Omniverse Launcher from NVIDIA Developer website"}),"\n",(0,o.jsx)(e.li,{children:'Search for "Isaac Sim" in the extensions catalog'}),"\n",(0,o.jsx)(e.li,{children:"Install the latest version (recommended: Isaac Sim 2023.1.1 or later)"}),"\n"]}),"\n",(0,o.jsx)(e.h4,{id:"method-2-docker-container-production",children:"Method 2: Docker Container (Production)"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-bash",children:'# Pull the latest Isaac Sim container\ndocker pull nvcr.io/nvidia/isaac-sim:latest\n\n# Run Isaac Sim with GPU support\ndocker run --gpus all -it --rm \\\n  --network=host \\\n  --env "ACCEPT_EULA=Y" \\\n  --env "NVIDIA_VISIBLE_DEVICES=all" \\\n  --env "NVIDIA_DRIVER_CAPABILITIES=all" \\\n  --volume $(pwd)/isaac_sim_data:/isaac_sim_data \\\n  --volume /tmp/.X11-unix:/tmp/.X11-unix \\\n  --env "DISPLAY=$DISPLAY" \\\n  nvcr.io/nvidia/isaac-sim:latest\n'})}),"\n",(0,o.jsx)(e.h4,{id:"method-3-standalone-installation",children:"Method 3: Standalone Installation"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-bash",children:"# Download Isaac Sim from NVIDIA Developer website\n# Follow the installation instructions for your platform\n# Ensure proper GPU drivers and CUDA are installed\n"})}),"\n",(0,o.jsx)(e.h3,{id:"initial-configuration",children:"Initial Configuration"}),"\n",(0,o.jsx)(e.p,{children:"After installation, configure Isaac Sim for humanoid robotics:"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Launch Isaac Sim"})," from the Omniverse Launcher"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Set up workspace directory"})," for your projects"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Configure extensions"})," needed for robotics simulation"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"essential-extensions-for-humanoid-robotics",children:"Essential Extensions for Humanoid Robotics"}),"\n",(0,o.jsx)(e.p,{children:"Enable these extensions for humanoid robot simulation:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Isaac ROS Bridge"}),": ROS 2 integration"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Isaac Sensors"}),": Advanced sensor simulation"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Isaac Assets"}),": Robot and environment assets"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Isaac Navigation"}),": Path planning and navigation"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Isaac Manipulation"}),": Grasping and manipulation tools"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"creating-high-fidelity-humanoid-environments",children:"Creating High-Fidelity Humanoid Environments"}),"\n",(0,o.jsx)(e.h3,{id:"usd-scene-structure",children:"USD Scene Structure"}),"\n",(0,o.jsx)(e.p,{children:"Isaac Sim uses Universal Scene Description (USD) for scene management:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{children:"humanoid_scenes/\n\u251c\u2500\u2500 humanoid_test.usd          # Main scene file\n\u251c\u2500\u2500 assets/\n\u2502   \u251c\u2500\u2500 robots/\n\u2502   \u2502   \u251c\u2500\u2500 atlas.usd         # Humanoid robot models\n\u2502   \u2502   \u2514\u2500\u2500 simple_humanoid.usd\n\u2502   \u251c\u2500\u2500 environments/\n\u2502   \u2502   \u251c\u2500\u2500 kitchen.usd       # Environment models\n\u2502   \u2502   \u251c\u2500\u2500 office.usd\n\u2502   \u2502   \u2514\u2500\u2500 warehouse.usd\n\u2502   \u2514\u2500\u2500 objects/\n\u2502       \u251c\u2500\u2500 furniture.usd     # Interactive objects\n\u2502       \u2514\u2500\u2500 tools.usd\n\u2514\u2500\u2500 configs/\n    \u251c\u2500\u2500 robot_config.json     # Robot configuration\n    \u2514\u2500\u2500 scene_config.json     # Scene configuration\n"})}),"\n",(0,o.jsx)(e.h3,{id:"basic-scene-setup",children:"Basic Scene Setup"}),"\n",(0,o.jsx)(e.p,{children:"Create a simple humanoid scene in USD format:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-usda",children:'# humanoid_basic.usda\n#usda 1.0\n\ndef Xform "World"\n{\n    def Xform "GroundPlane"\n    {\n        def PhysicsMaterial "GroundMaterial"\n        {\n            float inputs:dynamicFriction = 0.5\n            float inputs:staticFriction = 0.5\n            float inputs:restitution = 0.1\n        }\n\n        def Cube "GroundPlaneCube"\n        {\n            double3 xformOp:translate = (0, 0, -0.5)\n            uniform double3 size = (100, 100, 1)\n            rel physics:material = </World/GroundPlane/GroundMaterial>\n            rel xformOp:ordered = ["xformOp:translate"]\n        }\n    }\n\n    def Xform "Lighting"\n    {\n        def DistantLight "DistantLight"\n        {\n            float intensity = 300\n            color3f color = (1, 1, 1)\n            float3 direction = (-0.5, -0.5, -1)\n        }\n\n        def DomeLight "DomeLight"\n        {\n            float intensity = 0.5\n            asset inputs:texture:file = @hdri.hdr@\n        }\n    }\n\n    # Humanoid robot will be added here\n}\n'})}),"\n",(0,o.jsx)(e.h3,{id:"physics-configuration-for-humanoid-simulation",children:"Physics Configuration for Humanoid Simulation"}),"\n",(0,o.jsx)(e.p,{children:"Configure PhysX parameters for realistic humanoid physics:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-usda",children:'# Physics scene configuration\ndef PhysicsScene "PhysicsScene"\n{\n    PhysicsSceneAPI "PhysicsScene" (\n        apiSchemas = ["PhysicsSceneAPI"]\n    )\n    {\n        float physics:gravity = -9.81\n        float physics:defaultPositionIterationCount = 8\n        float physics:defaultVelocityIterationCount = 4\n        float physics:simulationSubSteps = 1\n    }\n\n    # Contact offset configuration for stable contacts\n    def PhysicsMaterial "HumanoidMaterial"\n    {\n        float inputs:dynamicFriction = 0.7\n        float inputs:staticFriction = 0.8\n        float inputs:restitution = 0.1\n        float inputs:contactOffset = 0.001\n        float inputs:restOffset = 0.0\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h2,{id:"importing-and-configuring-humanoid-robots",children:"Importing and Configuring Humanoid Robots"}),"\n",(0,o.jsx)(e.h3,{id:"using-the-urdf-importer",children:"Using the URDF Importer"}),"\n",(0,o.jsx)(e.p,{children:"Isaac Sim includes a powerful URDF importer for bringing in humanoid robot models:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'# Import URDF robot into Isaac Sim\nimport omni\nfrom omni.isaac.core.utils.nucleus import get_assets_root_path\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\nfrom omni.isaac.core.utils.prims import get_prim_at_path\nfrom pxr import UsdPhysics\n\n# Import humanoid robot from URDF\ndef import_humanoid_robot(urdf_path, prim_path="/World/HumanoidRobot"):\n    # Add URDF reference to stage\n    add_reference_to_stage(\n        usd_path=urdf_path,\n        prim_path=prim_path\n    )\n\n    # Configure physics properties for the robot\n    configure_robot_physics(prim_path)\n\ndef configure_robot_physics(robot_path):\n    # Get the robot prim\n    robot_prim = get_prim_at_path(robot_path)\n\n    # Set up joint properties for humanoid locomotion\n    setup_joint_properties(robot_path)\n\n    # Configure collision properties\n    setup_collision_properties(robot_path)\n\ndef setup_joint_properties(robot_path):\n    # Configure joints for realistic humanoid movement\n    import omni.kit.commands\n\n    # Example: Configure hip joint with proper limits and dynamics\n    omni.kit.commands.execute(\n        "ChangeGenericJointProperties",\n        path=f"{robot_path}/left_hip_joint",\n        lower_limit=-1.57,\n        upper_limit=1.57,\n        stiffness=1000.0,\n        damping=100.0,\n        armature=0.1\n    )\n'})}),"\n",(0,o.jsx)(e.h3,{id:"physics-joints-configuration",children:"Physics Joints Configuration"}),"\n",(0,o.jsx)(e.p,{children:"For realistic humanoid movement, configure joints with appropriate properties:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'def setup_humanoid_joints(robot_path):\n    """Configure joints for realistic humanoid physics"""\n\n    # Hip joints - critical for bipedal locomotion\n    configure_joint(\n        f"{robot_path}/left_hip_joint",\n        joint_type="Joint",\n        lower_limit=-1.57,  # -90 degrees\n        upper_limit=1.57,   # 90 degrees\n        stiffness=2000.0,\n        damping=200.0,\n        max_force=500.0\n    )\n\n    # Knee joints - important for walking\n    configure_joint(\n        f"{robot_path}/left_knee_joint",\n        joint_type="Joint",\n        lower_limit=0.0,    # No backward bending\n        upper_limit=2.35,   # ~135 degrees\n        stiffness=1500.0,\n        damping=150.0,\n        max_force=400.0\n    )\n\n    # Ankle joints - crucial for balance\n    configure_joint(\n        f"{robot_path}/left_ankle_joint",\n        joint_type="Joint",\n        lower_limit=-0.52,  # -30 degrees\n        upper_limit=0.52,   # 30 degrees\n        stiffness=800.0,\n        damping=80.0,\n        max_force=200.0\n    )\n\n    # Shoulder joints - for manipulation\n    configure_joint(\n        f"{robot_path}/left_shoulder_joint",\n        joint_type="Joint",\n        lower_limit=-2.09,  # -120 degrees\n        upper_limit=1.57,   # 90 degrees\n        stiffness=1000.0,\n        damping=100.0,\n        max_force=300.0\n    )\n'})}),"\n",(0,o.jsx)(e.h2,{id:"advanced-sensor-simulation",children:"Advanced Sensor Simulation"}),"\n",(0,o.jsx)(e.h3,{id:"camera-simulation-for-vision-systems",children:"Camera Simulation for Vision Systems"}),"\n",(0,o.jsx)(e.p,{children:"Configure realistic camera sensors for the Vision component of the VLA pipeline:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'from omni.isaac.sensor import Camera\nimport numpy as np\n\ndef setup_robot_cameras(robot_path):\n    """Set up cameras for humanoid robot vision system"""\n\n    # Head-mounted RGB camera\n    head_camera = Camera(\n        prim_path=f"{robot_path}/head_camera",\n        frequency=30,  # Hz\n        resolution=(640, 480),\n        position=np.array([0.1, 0.0, 0.0]),  # Offset from head center\n        orientation=np.array([0, 0, 0, 1])   # Default orientation\n    )\n\n    # Configure camera properties for realistic simulation\n    head_camera.add_motion_vectors_to_frame()\n    head_camera.add_ground_truth_to_frame(\n        "/World/GroundPlane",\n        "/World/Objects"\n    )\n\n    # Depth camera for 3D perception\n    depth_camera = Camera(\n        prim_path=f"{robot_path}/depth_camera",\n        frequency=30,\n        resolution=(640, 480),\n        position=np.array([0.1, 0.0, 0.0]),\n        orientation=np.array([0, 0, 0, 1])\n    )\n\n    # Add depth information to frame\n    depth_camera.add_distance_to_image_plane_to_frame()\n\n    return head_camera, depth_camera\n\ndef setup_perception_pipeline(camera):\n    """Set up perception pipeline for the camera"""\n    # Add various perception outputs\n    camera.add_distortion_to_frame()  # Lens distortion\n    camera.add_fisheye_to_frame()     # Fisheye effects if needed\n    camera.add_occupancy_grid_to_frame()  # For navigation\n'})}),"\n",(0,o.jsx)(e.h3,{id:"imu-simulation-for-balance-feedback",children:"IMU Simulation for Balance Feedback"}),"\n",(0,o.jsx)(e.p,{children:"Configure IMU sensors critical for the Real-Time Validation principle:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'def setup_imu_sensors(robot_path):\n    """Set up IMU sensors for balance feedback"""\n\n    # Main IMU in torso for balance control\n    torso_imu = RigidBodyImu(\n        prim_path=f"{robot_path}/torso_imu",\n        position=np.array([0.0, 0.0, 0.2]),  # Upper torso\n        orientation=np.array([0, 0, 0, 1]),\n        update_frequency=1000,  # High frequency for balance (1000Hz)\n        noise_density=2e-4,     # Gyro noise density\n        random_walk=2e-5,       # Gyro random walk\n        bias_correlation_time=1000,\n        velocity_random_walk=1.7e-2,  # Accel noise\n        bias_acc_correlation_time=300\n    )\n\n    # Additional IMUs for better state estimation\n    head_imu = RigidBodyImu(\n        prim_path=f"{robot_path}/head_imu",\n        position=np.array([0.0, 0.0, 0.5]),  # Head position\n        update_frequency=500  # Lower frequency, less critical\n    )\n\n    return torso_imu, head_imu\n\nclass RigidBodyImu:\n    """Custom IMU class for humanoid applications"""\n    def __init__(self, prim_path, position, orientation, update_frequency=100, **kwargs):\n        self.prim_path = prim_path\n        self.position = position\n        self.orientation = orientation\n        self.update_frequency = update_frequency\n        self.noise_params = kwargs\n\n        # Initialize IMU in Isaac Sim\n        self._create_imu()\n\n    def _create_imu(self):\n        """Create the IMU sensor in the simulation"""\n        # Implementation would create the actual IMU in Isaac Sim\n        pass\n\n    def get_imu_data(self):\n        """Get IMU data with realistic noise and bias"""\n        # Return realistic IMU measurements\n        pass\n'})}),"\n",(0,o.jsx)(e.h3,{id:"forcetorque-sensors-for-manipulation",children:"Force/Torque Sensors for Manipulation"}),"\n",(0,o.jsx)(e.p,{children:"Configure force/torque sensors for dexterous manipulation:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'def setup_force_torque_sensors(robot_path):\n    """Set up force/torque sensors for manipulation"""\n\n    # Sensors in robot hands for manipulation feedback\n    left_hand_ft = setup_hand_force_torque(f"{robot_path}/left_hand")\n    right_hand_ft = setup_hand_force_torque(f"{robot_path}/right_hand")\n\n    # Sensors in feet for balance detection\n    left_foot_ft = setup_foot_force_torque(f"{robot_path}/left_foot")\n    right_foot_ft = setup_foot_force_torque(f"{robot_path}/right_foot")\n\n    return {\n        \'left_hand\': left_hand_ft,\n        \'right_hand\': right_hand_ft,\n        \'left_foot\': left_foot_ft,\n        \'right_foot\': right_foot_ft\n    }\n\ndef setup_hand_force_torque(hand_path):\n    """Set up force/torque sensor in hand"""\n    from omni.isaac.core.sensors import ForceSensor\n\n    ft_sensor = ForceSensor(\n        prim_path=f"{hand_path}/ft_sensor",\n        position=np.array([0.0, 0.0, -0.05]),  # At the end of the hand\n        update_frequency=100,  # 100Hz for manipulation\n        force_range=[-100, 100],  # Up to 100N in each direction\n        torque_range=[-10, 10]   # Up to 10 Nm torque\n    )\n\n    return ft_sensor\n\ndef setup_foot_force_torque(foot_path):\n    """Set up force/torque sensor in foot for balance"""\n    from omni.isaac.core.sensors import ForceSensor\n\n    ft_sensor = ForceSensor(\n        prim_path=f"{foot_path}/ft_sensor",\n        position=np.array([0.0, 0.0, -0.01]),  # Top of foot\n        update_frequency=1000,  # High frequency for balance (matches IMU)\n        force_range=[-1000, 1000],  # Higher range for body weight support\n        torque_range=[-50, 50]\n    )\n\n    return ft_sensor\n'})}),"\n",(0,o.jsx)(e.h2,{id:"ros-2-integration",children:"ROS 2 Integration"}),"\n",(0,o.jsx)(e.h3,{id:"setting-up-ros-bridge",children:"Setting up ROS Bridge"}),"\n",(0,o.jsx)(e.p,{children:"Isaac Sim provides excellent ROS 2 integration for the Vision-Language-Action pipeline:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'import rospy\nfrom sensor_msgs.msg import JointState, Imu, Image\nfrom geometry_msgs.msg import Twist\nfrom std_msgs.msg import String\nfrom cv_bridge import CvBridge\nimport numpy as np\n\nclass IsaacSimROSBridge:\n    def __init__(self):\n        # Initialize ROS node\n        rospy.init_node(\'isaac_sim_ros_bridge\', anonymous=True)\n\n        # Bridge instance\n        self.bridge = CvBridge()\n\n        # Publishers\n        self.joint_pub = rospy.Publisher(\'/joint_states\', JointState, queue_size=10)\n        self.imu_pub = rospy.Publisher(\'/imu/data\', Imu, queue_size=10)\n        self.camera_pub = rospy.Publisher(\'/camera/image_raw\', Image, queue_size=10)\n\n        # Subscribers\n        self.cmd_sub = rospy.Subscriber(\'/cmd_vel\', Twist, self.cmd_vel_callback)\n        self.speech_sub = rospy.Subscriber(\'/speech_commands\', String, self.speech_callback)\n\n        # Timer for publishing sensor data\n        self.publish_timer = rospy.Timer(rospy.Duration(0.01), self.publish_sensor_data)  # 100Hz\n\n        # Robot state tracking\n        self.robot_state = {}\n\n    def cmd_vel_callback(self, msg):\n        """Handle velocity commands from ROS"""\n        # Convert ROS velocity command to Isaac Sim robot control\n        self.apply_velocity_command(msg.linear, msg.angular)\n\n    def speech_callback(self, msg):\n        """Handle speech commands from ROS"""\n        # Process speech command and update robot behavior\n        self.process_speech_command(msg.data)\n\n    def publish_sensor_data(self, event):\n        """Publish sensor data to ROS topics"""\n        # Publish joint states\n        joint_msg = self.create_joint_state_msg()\n        self.joint_pub.publish(joint_msg)\n\n        # Publish IMU data\n        imu_msg = self.create_imu_msg()\n        self.imu_pub.publish(imu_msg)\n\n        # Publish camera data\n        camera_msg = self.create_camera_msg()\n        self.camera_pub.publish(camera_msg)\n\n    def create_joint_state_msg(self):\n        """Create joint state message from Isaac Sim robot"""\n        msg = JointState()\n        msg.header.stamp = rospy.Time.now()\n        msg.header.frame_id = "base_link"\n\n        # Get joint positions from Isaac Sim\n        joint_names, joint_positions, joint_velocities = self.get_robot_joint_states()\n\n        msg.name = joint_names\n        msg.position = joint_positions\n        msg.velocity = joint_velocities\n\n        return msg\n\n    def create_imu_msg(self):\n        """Create IMU message from Isaac Sim IMU sensor"""\n        msg = Imu()\n        msg.header.stamp = rospy.Time.now()\n        msg.header.frame_id = "torso_imu"\n\n        # Get IMU data from Isaac Sim\n        orientation, angular_velocity, linear_acceleration = self.get_imu_data()\n\n        # Set orientation (simplified)\n        msg.orientation.x = orientation[0]\n        msg.orientation.y = orientation[1]\n        msg.orientation.z = orientation[2]\n        msg.orientation.w = orientation[3]\n\n        # Set angular velocity\n        msg.angular_velocity.x = angular_velocity[0]\n        msg.angular_velocity.y = angular_velocity[1]\n        msg.angular_velocity.z = angular_velocity[2]\n\n        # Set linear acceleration\n        msg.linear_acceleration.x = linear_acceleration[0]\n        msg.linear_acceleration.y = linear_acceleration[1]\n        msg.linear_acceleration.z = linear_acceleration[2]\n\n        return msg\n\n    def create_camera_msg(self):\n        """Create camera message from Isaac Sim camera"""\n        # Get camera image from Isaac Sim\n        image_data, width, height = self.get_camera_image()\n\n        # Convert to ROS Image message\n        msg = self.bridge.cv2_to_imgmsg(image_data, encoding="rgb8")\n        msg.header.stamp = rospy.Time.now()\n        msg.header.frame_id = "camera_link"\n\n        return msg\n\n    def get_robot_joint_states(self):\n        """Get current robot joint states from Isaac Sim"""\n        # This would interface with Isaac Sim\'s physics engine\n        # Implementation depends on the specific robot configuration\n        joint_names = ["left_hip_joint", "left_knee_joint", "left_ankle_joint",\n                      "right_hip_joint", "right_knee_joint", "right_ankle_joint"]\n        joint_positions = [0.0] * len(joint_names)  # Placeholder\n        joint_velocities = [0.0] * len(joint_names)  # Placeholder\n\n        return joint_names, joint_positions, joint_velocities\n\n    def get_imu_data(self):\n        """Get IMU data from Isaac Sim"""\n        # Placeholder implementation\n        orientation = [0.0, 0.0, 0.0, 1.0]  # Quaternion (x, y, z, w)\n        angular_velocity = [0.0, 0.0, 0.0]  # rad/s\n        linear_acceleration = [0.0, 0.0, -9.8]  # m/s^2\n\n        return orientation, angular_velocity, linear_acceleration\n\n    def get_camera_image(self):\n        """Get camera image from Isaac Sim"""\n        # Placeholder implementation\n        # In practice, this would get the actual rendered image from Isaac Sim\n        width, height = 640, 480\n        image_data = np.zeros((height, width, 3), dtype=np.uint8)  # Placeholder\n\n        return image_data, width, height\n'})}),"\n",(0,o.jsx)(e.h2,{id:"high-fidelity-physics-simulation",children:"High-Fidelity Physics Simulation"}),"\n",(0,o.jsx)(e.h3,{id:"advanced-physx-configuration",children:"Advanced PhysX Configuration"}),"\n",(0,o.jsx)(e.p,{children:"Configure PhysX for maximum realism in humanoid simulation:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"def configure_advanced_physics():\n    \"\"\"Configure advanced PhysX parameters for humanoid simulation\"\"\"\n\n    # Set global physics parameters\n    from omni.physx import get_physx_interface\n\n    physx = get_physx_interface()\n\n    # Configure solver settings for stability\n    physx.set_parameter(\"SolverType\", 0)  # 0=PBD, 1=TGS\n    physx.set_parameter(\"EnableEnhancedDeterminism\", True)\n    physx.set_parameter(\"BounceThresholdVelocity\", 0.5)\n\n    # Configure collision settings\n    physx.set_parameter(\"SleepThreshold\", 0.005)\n    physx.set_parameter(\"StabilizationThreshold\", 0.02)\n\n    # Configure broadphase settings\n    physx.set_parameter(\"BroadphaseType\", 0)  # 0=SAP, 1=MBP, 2=PV32\n\ndef setup_humanoid_collision_geometry(robot_path):\n    \"\"\"Set up detailed collision geometry for humanoid robot\"\"\"\n\n    # Define collision shapes for each body part\n    collision_config = {\n        'torso': {\n            'shape': 'capsule',\n            'dimensions': [0.15, 0.6],  # radius, height\n            'position': [0, 0, 0.3]\n        },\n        'head': {\n            'shape': 'sphere',\n            'dimensions': [0.1],  # radius\n            'position': [0, 0, 0.75]\n        },\n        'upper_arm': {\n            'shape': 'capsule',\n            'dimensions': [0.05, 0.3],  # radius, length\n            'position': [0, 0, 0.15]\n        },\n        'lower_arm': {\n            'shape': 'capsule',\n            'dimensions': [0.04, 0.3],\n            'position': [0, 0, 0.15]\n        },\n        'thigh': {\n            'shape': 'capsule',\n            'dimensions': [0.08, 0.4],\n            'position': [0, 0, 0.2]\n        },\n        'calf': {\n            'shape': 'capsule',\n            'dimensions': [0.07, 0.4],\n            'position': [0, 0, 0.2]\n        },\n        'foot': {\n            'shape': 'box',\n            'dimensions': [0.2, 0.1, 0.05],\n            'position': [0.05, 0, -0.025]  # Offset for natural foot position\n        }\n    }\n\n    # Apply collision geometry to robot parts\n    for part_name, config in collision_config.items():\n        apply_collision_geometry(f\"{robot_path}/{part_name}\", config)\n\ndef apply_collision_geometry(prim_path, config):\n    \"\"\"Apply collision geometry to a robot part\"\"\"\n    from omni.isaac.core.utils.prims import get_prim_at_path\n    from omni.isaac.core.utils.stage import get_current_stage\n    from pxr import UsdPhysics, Gf, Sdf\n\n    stage = get_current_stage()\n    prim = stage.GetPrimAtPath(prim_path)\n\n    if not prim.IsValid():\n        print(f\"Prim {prim_path} not found\")\n        return\n\n    # Create collision API for the prim\n    UsdPhysics.CollisionAPI.Apply(prim)\n\n    # Set collision properties\n    collision_api = UsdPhysics.CollisionAPI(prim)\n    collision_api.CreateCollisionEnabledAttr(True)\n\n    # Create collision approximation based on shape\n    if config['shape'] == 'capsule':\n        # Create capsule collision shape\n        collision_api.CreateApproximationAttr(\"capsule\")\n    elif config['shape'] == 'sphere':\n        collision_api.CreateApproximationAttr(\"sphere\")\n    elif config['shape'] == 'box':\n        collision_api.CreateApproximationAttr(\"convexHull\")\n\ndef setup_realistic_contact_materials():\n    \"\"\"Set up realistic contact materials for humanoid interaction\"\"\"\n\n    # Different materials for different robot parts\n    material_config = {\n        'foot_sole': {\n            'static_friction': 0.8,\n            'dynamic_friction': 0.7,\n            'restitution': 0.1,\n            'compliance': 1e-6\n        },\n        'hand_grip': {\n            'static_friction': 0.9,\n            'dynamic_friction': 0.8,\n            'restitution': 0.05,\n            'compliance': 1e-5\n        },\n        'body': {\n            'static_friction': 0.3,\n            'dynamic_friction': 0.2,\n            'restitution': 0.2,\n            'compliance': 1e-4\n        }\n    }\n\n    return material_config\n"})}),"\n",(0,o.jsx)(e.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,o.jsx)(e.h3,{id:"simulation-optimization-techniques",children:"Simulation Optimization Techniques"}),"\n",(0,o.jsx)(e.p,{children:"For high-fidelity humanoid simulation while maintaining performance:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'def optimize_simulation_performance():\n    """Optimize Isaac Sim performance for humanoid simulation"""\n\n    # Reduce unnecessary physics updates for static objects\n    disable_physics_for_static_objects()\n\n    # Optimize rendering settings\n    optimize_rendering_settings()\n\n    # Configure simulation sub-stepping\n    configure_sub_stepping()\n\n    # Set up level-of-detail for complex models\n    setup_lod_system()\n\ndef disable_physics_for_static_objects():\n    """Disable physics for objects that don\'t need it"""\n    from omni.isaac.core.utils.prims import get_prim_at_path\n    from pxr import UsdPhysics\n\n    # Example: Disable physics for ground plane if it\'s static\n    ground_prim = get_prim_at_path("/World/GroundPlane")\n    if ground_prim.IsValid():\n        rigid_body_api = UsdPhysics.RigidBodyAPI(ground_prim)\n        if rigid_body_api:\n            rigid_body_api.GetRigidBodyEnabledAttr().Set(False)\n\ndef optimize_rendering_settings():\n    """Optimize rendering for performance"""\n    import omni\n    from omni import kit\n\n    # Reduce rendering quality for non-visual sensors\n    config = {\n        "rtx-defaults": {\n            "enabled": True,\n            "maxDiffuseBounces": 2,\n            "maxReflectionRefractionBounces": 2,\n            "maxScatterBounces": 2\n        },\n        "renderer-lighting": {\n            "enable": True,\n            "enableDenoising": False  # Disable for performance\n        }\n    }\n\n    for key, value in config.items():\n        for subkey, subvalue in value.items():\n            kit.app.get_framework().get_setting_store().set_value(\n                f"{key}.{subkey}", subvalue\n            )\n\ndef configure_sub_stepping():\n    """Configure sub-stepping for stable simulation"""\n    from omni.physx import get_physx_interface\n\n    physx = get_physx_interface()\n\n    # Use sub-stepping for complex contact scenarios\n    physx.set_parameter("SimulationSubsteps", 4)\n    physx.set_parameter("MaxBiasClamp", 10.0)\n\ndef setup_lod_system():\n    """Set up level-of-detail for performance"""\n    # Implementation would involve creating LOD groups\n    # for complex models that are far from the camera\n    pass\n'})}),"\n",(0,o.jsx)(e.h2,{id:"constitution-alignment",children:"Constitution Alignment"}),"\n",(0,o.jsx)(e.p,{children:"This chapter addresses several constitutional requirements:"}),"\n",(0,o.jsx)(e.h3,{id:"sim-to-real-rigor-principle-iii",children:"Sim-to-Real Rigor (Principle III)"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"High-fidelity physics simulation using PhysX engine"}),"\n",(0,o.jsx)(e.li,{children:"Realistic sensor modeling matching hardware specifications"}),"\n",(0,o.jsx)(e.li,{children:"Accurate contact dynamics for humanoid locomotion"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"real-time-validation-principle-iv",children:"Real-Time Validation (Principle IV)"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"High-frequency IMU simulation (1000Hz) for balance feedback"}),"\n",(0,o.jsx)(e.li,{children:"Proper QoS profiles for real-time sensor data"}),"\n",(0,o.jsx)(e.li,{children:"Performance optimization for real-time operation"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"target-hardware-optimization",children:"Target Hardware Optimization"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Configuration optimized for RTX 4070 Ti and Isaac Sim requirements"}),"\n",(0,o.jsx)(e.li,{children:"GPU-accelerated physics and rendering"}),"\n",(0,o.jsx)(e.li,{children:"Performance settings appropriate for target hardware"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"visualization-requirements-key-standard-ii",children:"Visualization Requirements (Key Standard II)"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"High-fidelity rendering with RTX technology"}),"\n",(0,o.jsx)(e.li,{children:"Photorealistic environments for synthetic data generation"}),"\n",(0,o.jsx)(e.li,{children:"Proper material and lighting setup"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"practical-examples",children:"Practical Examples"}),"\n",(0,o.jsx)(e.h3,{id:"example-1-humanoid-balance-testing-environment",children:"Example 1: Humanoid Balance Testing Environment"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'def create_balance_test_environment():\n    """Create a specialized environment for humanoid balance testing"""\n\n    # Import basic scene\n    from omni.isaac.core.utils.stage import add_reference_to_stage\n    from omni.isaac.core.utils.nucleus import get_assets_root_path\n\n    # Create the scene\n    stage_path = "/Isaac/Environments/Simple_Room/simple_room.usd"\n    add_reference_to_stage(get_assets_root_path() + stage_path, "/World")\n\n    # Add balance testing elements\n    create_narrow_beam("/World/NarrowBeam")\n    create_sloped_surface("/World/Slope")\n    create_unstable_surface("/World/UnstableSurface")\n\n    # Add safety boundaries\n    create_safety_boundary("/World/Boundary")\n\ndef create_narrow_beam(prim_path):\n    """Create a narrow beam for balance testing"""\n    from omni.isaac.core.utils.prims import create_prim\n    from omni.isaac.core.utils.stage import get_current_stage\n    from pxr import Gf\n\n    # Create a narrow beam for balance testing\n    create_prim(\n        prim_path=prim_path,\n        prim_type="Cylinder",\n        position=(2.0, 0.0, 0.05),\n        orientation=(0.0, 0.0, 0.0, 1.0),\n        scale=(1.0, 0.05, 0.05)  # Long, narrow beam\n    )\n\n    # Add collision and physics properties\n    stage = get_current_stage()\n    beam_prim = stage.GetPrimAtPath(prim_path)\n\n    from pxr import UsdPhysics\n    UsdPhysics.CollisionAPI.Apply(beam_prim)\n    rigid_body_api = UsdPhysics.RigidBodyAPI.Apply(beam_prim)\n    rigid_body_api.GetRigidBodyEnabledAttr().Set(False)  # Static object\n\ndef create_sloped_surface(prim_path):\n    """Create a sloped surface for balance testing"""\n    from omni.isaac.core.utils.prims import create_prim\n\n    # Create a sloped plane\n    create_prim(\n        prim_path=prim_path,\n        prim_type="Plane",\n        position=(0.0, 2.0, 0.0),\n        orientation=(0.0, 0.0, 0.2, 0.98),  # 20 degree slope\n        scale=(2.0, 2.0, 1.0)\n    )\n\ndef setup_balance_control_demo():\n    """Set up a complete balance control demonstration"""\n\n    # Import humanoid robot\n    robot_path = "/World/HumanoidRobot"\n    urdf_path = "path/to/humanoid.urdf"  # Replace with actual path\n\n    # Import and configure robot\n    import_humanoid_robot(urdf_path, robot_path)\n\n    # Configure physics for balance\n    configure_robot_physics(robot_path)\n\n    # Add sensors\n    setup_robot_cameras(robot_path)\n    setup_imu_sensors(robot_path)\n\n    # Set up ROS bridge for control\n    ros_bridge = IsaacSimROSBridge()\n\n    print("Balance control demo environment ready!")\n'})}),"\n",(0,o.jsx)(e.h3,{id:"example-2-manipulation-training-environment",children:"Example 2: Manipulation Training Environment"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'def create_manipulation_training_environment():\n    """Create an environment for manipulation skill training"""\n\n    # Set up a kitchen-like environment\n    setup_kitchen_environment()\n\n    # Add training objects with various properties\n    add_training_objects()\n\n    # Configure lighting for vision tasks\n    configure_vision_lighting()\n\n    # Set up data collection for synthetic dataset\n    setup_data_collection()\n\ndef setup_kitchen_environment():\n    """Set up a kitchen environment for manipulation tasks"""\n\n    # Create counter with appropriate height\n    create_counter("/World/Counter", position=(1.5, 0, 0.9))\n\n    # Add cabinets\n    create_cabinet("/World/Cabinet", position=(1.5, 1, 0.9))\n\n    # Add table\n    create_table("/World/Table", position=(-1.5, 0, 0.75))\n\ndef create_counter(prim_path, position):\n    """Create a kitchen counter"""\n    from omni.isaac.core.utils.prims import create_prim\n\n    create_prim(\n        prim_path=prim_path,\n        prim_type="Cube",\n        position=position,\n        scale=(1.2, 0.6, 0.8)\n    )\n\n    # Add physics properties\n    from omni.isaac.core.utils.stage import get_current_stage\n    from pxr import UsdPhysics\n    stage = get_current_stage()\n    counter_prim = stage.GetPrimAtPath(prim_path)\n    UsdPhysics.CollisionAPI.Apply(counter_prim)\n\ndef add_training_objects():\n    """Add various objects for manipulation training"""\n\n    objects_config = [\n        {"name": "RedCup", "type": "Cylinder", "size": (0.05, 0.1), "color": (1, 0, 0)},\n        {"name": "BlueBox", "type": "Cube", "size": (0.08, 0.08, 0.08), "color": (0, 0, 1)},\n        {"name": "GreenBottle", "type": "Cylinder", "size": (0.03, 0.15), "color": (0, 1, 0)},\n        {"name": "YellowPyramid", "type": "Cone", "size": (0.06, 0.1), "color": (1, 1, 0)}\n    ]\n\n    positions = [(1.6, -0.2, 0.95), (1.6, 0.1, 0.95), (1.6, 0.3, 0.95), (1.6, 0.0, 1.05)]\n\n    for i, obj_config in enumerate(objects_config):\n        create_training_object(\n            f"/World/Objects/{obj_config[\'name\']}",\n            obj_config,\n            positions[i]\n        )\n\ndef create_training_object(prim_path, config, position):\n    """Create a training object with specific properties"""\n    from omni.isaac.core.utils.prims import create_prim\n    from omni.isaac.core.utils.stage import get_current_stage\n    from pxr import UsdPhysics, Gf\n\n    # Create the object\n    if config["type"] == "Cylinder":\n        create_prim(\n            prim_path=prim_path,\n            prim_type="Cylinder",\n            position=position,\n            scale=(config["size"][0], config["size"][0], config["size"][1])\n        )\n    elif config["type"] == "Cube":\n        create_prim(\n            prim_path=prim_path,\n            prim_type="Cube",\n            position=position,\n            scale=config["size"]\n        )\n\n    # Add physics properties\n    stage = get_current_stage()\n    obj_prim = stage.GetPrimAtPath(prim_path)\n\n    UsdPhysics.CollisionAPI.Apply(obj_prim)\n    rigid_body_api = UsdPhysics.RigidBodyAPI.Apply(obj_prim)\n\n    # Set mass based on size\n    volume = calculate_volume(config["type"], config["size"])\n    mass = volume * 1000  # Assume density of 1000 kg/m^3 (water-like)\n    rigid_body_api.CreateMassAttr(mass)\n\ndef calculate_volume(obj_type, size):\n    """Calculate volume of an object"""\n    if obj_type == "Cylinder":\n        radius, height = size[0], size[2] if len(size) > 2 else size[1]\n        return 3.14159 * radius * radius * height\n    elif obj_type == "Cube":\n        return size[0] * size[1] * size[2] if len(size) > 2 else size[0] * size[0] * size[1]\n    return 0.1  # Default volume\n'})}),"\n",(0,o.jsx)(e.h2,{id:"exercises",children:"Exercises"}),"\n",(0,o.jsx)(e.h3,{id:"exercise-1-physics-configuration",children:"Exercise 1: Physics Configuration"}),"\n",(0,o.jsx)(e.p,{children:"Configure a humanoid robot model in Isaac Sim with:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Proper joint limits and dynamics for bipedal locomotion"}),"\n",(0,o.jsx)(e.li,{children:"Realistic mass distribution and inertial properties"}),"\n",(0,o.jsx)(e.li,{children:"Appropriate collision geometry for stable simulation"}),"\n",(0,o.jsx)(e.li,{children:"Performance optimization settings"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"exercise-2-sensor-integration",children:"Exercise 2: Sensor Integration"}),"\n",(0,o.jsx)(e.p,{children:"Set up a complete sensor suite for a humanoid robot that includes:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"RGB and depth cameras with realistic parameters"}),"\n",(0,o.jsx)(e.li,{children:"High-frequency IMU for balance feedback (1000Hz)"}),"\n",(0,o.jsx)(e.li,{children:"Force/torque sensors in hands and feet"}),"\n",(0,o.jsx)(e.li,{children:"Proper ROS 2 integration for all sensors"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"exercise-3-environment-creation",children:"Exercise 3: Environment Creation"}),"\n",(0,o.jsx)(e.p,{children:"Create a complex environment for humanoid robot training that includes:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Multiple rooms with human-centered furniture"}),"\n",(0,o.jsx)(e.li,{children:"Various surfaces with different friction properties"}),"\n",(0,o.jsx)(e.li,{children:"Interactive objects for manipulation tasks"}),"\n",(0,o.jsx)(e.li,{children:"Proper lighting for vision system training"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsx)(e.p,{children:"NVIDIA Isaac Sim provides state-of-the-art simulation capabilities essential for developing humanoid robots that can operate effectively in real-world environments. The high-fidelity physics simulation, realistic sensor modeling, and photorealistic rendering support the Vision-Language-Action pipeline and enable effective sim-to-real transfer of learned behaviors. Understanding Isaac Sim fundamentals is crucial for creating digital twins that accurately represent the challenges of humanoid robotics in human-centered environments."}),"\n",(0,o.jsx)(e.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:'"NVIDIA Isaac Sim Documentation" - Official Isaac Sim user guide'}),"\n",(0,o.jsx)(e.li,{children:'"PhysX SDK Guide" - NVIDIA PhysX physics engine documentation'}),"\n",(0,o.jsx)(e.li,{children:'"Universal Scene Description (USD) Specification"'}),"\n",(0,o.jsx)(e.li,{children:'"Omniverse Developer Documentation"'}),"\n",(0,o.jsx)(e.li,{children:'"Robotics Simulation with Isaac Sim" - NVIDIA Developer articles'}),"\n"]})]})}function m(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(d,{...n})}):d(n)}}}]);