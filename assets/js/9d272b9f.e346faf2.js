"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[600],{720(n,e,i){i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>u,frontMatter:()=>r,metadata:()=>o,toc:()=>d});const o=JSON.parse('{"id":"chapters/module-2-ros/chapter-8-ros2-tools","title":"Chapter 8 - ROS 2 Tools: Rviz, RQt, TF2","description":"Covering essential ROS 2 tools including Rviz, RQt, and TF2 for humanoid robots","source":"@site/docs/chapters/module-2-ros/chapter-8-ros2-tools.md","sourceDirName":"chapters/module-2-ros","slug":"/chapters/module-2-ros/chapter-8-ros2-tools","permalink":"/docs/chapters/module-2-ros/chapter-8-ros2-tools","draft":false,"unlisted":false,"editUrl":"https://github.com/RIMZAASAD/Robotic-ai-Book/edit/main/website/docs/chapters/module-2-ros/chapter-8-ros2-tools.md","tags":[],"version":"current","frontMatter":{"title":"Chapter 8 - ROS 2 Tools: Rviz, RQt, TF2","module":"ROS 2: The Robotic Nervous System","chapter":8,"description":"Covering essential ROS 2 tools including Rviz, RQt, and TF2 for humanoid robots","learningObjectives":["Use RViz2 for robot visualization and debugging","Apply RQt for custom GUI development","Implement TF2 for coordinate frame management"],"prerequisites":["chapter-7-urdf-xacro"],"difficulty":"intermediate"},"sidebar":"textbookSidebar","previous":{"title":"Chapter 7: URDF & XACRO for Humanoid Robots","permalink":"/docs/chapters/module-2-ros/chapter-7-urdf-xacro"},"next":{"title":"Chapter 9: Gazebo Simulation Setup","permalink":"/docs/chapters/module-3-simulation/chapter-9-gazebo-setup"}}');var t=i(4848),a=i(8453);const r={title:"Chapter 8 - ROS 2 Tools: Rviz, RQt, TF2",module:"ROS 2: The Robotic Nervous System",chapter:8,description:"Covering essential ROS 2 tools including Rviz, RQt, and TF2 for humanoid robots",learningObjectives:["Use RViz2 for robot visualization and debugging","Apply RQt for custom GUI development","Implement TF2 for coordinate frame management"],prerequisites:["chapter-7-urdf-xacro"],difficulty:"intermediate"},s=void 0,l={},d=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction",id:"introduction",level:2},{value:"RViz2: 3D Visualization for Humanoid Robots",id:"rviz2-3d-visualization-for-humanoid-robots",level:2},{value:"Core Components of RViz2",id:"core-components-of-rviz2",level:3},{value:"Displays Panel",id:"displays-panel",level:4},{value:"Views Panel",id:"views-panel",level:4},{value:"Setting Up RViz2 for Humanoid Robots",id:"setting-up-rviz2-for-humanoid-robots",level:3},{value:"Basic Configuration File",id:"basic-configuration-file",level:4},{value:"RViz2 Plugins for Humanoid Robotics",id:"rviz2-plugins-for-humanoid-robotics",level:3},{value:"RobotModel Display",id:"robotmodel-display",level:4},{value:"TF Display",id:"tf-display",level:4},{value:"Camera Display",id:"camera-display",level:4},{value:"Launching RViz2 with Configuration",id:"launching-rviz2-with-configuration",level:3},{value:"RQt: Custom GUI Development",id:"rqt-custom-gui-development",level:2},{value:"Core RQt Concepts",id:"core-rqt-concepts",level:3},{value:"Plugin Architecture",id:"plugin-architecture",level:4},{value:"Creating a Custom RQt Plugin",id:"creating-a-custom-rqt-plugin",level:3},{value:"Plugin Structure",id:"plugin-structure",level:4},{value:"Plugin Implementation",id:"plugin-implementation",level:4},{value:"Plugin Configuration",id:"plugin-configuration",level:4},{value:"Package Configuration",id:"package-configuration",level:4},{value:"TF2: Transform Library for Coordinate Management",id:"tf2-transform-library-for-coordinate-management",level:2},{value:"TF2 Core Concepts",id:"tf2-core-concepts",level:3},{value:"Coordinate Frames",id:"coordinate-frames",level:4},{value:"Transform Messages",id:"transform-messages",level:4},{value:"TF2 in Python",id:"tf2-in-python",level:3},{value:"TF2 for Humanoid Robot Applications",id:"tf2-for-humanoid-robot-applications",level:3},{value:"Vision Integration",id:"vision-integration",level:4},{value:"Manipulation Planning",id:"manipulation-planning",level:4},{value:"Integration with Vision-Language-Action Pipeline",id:"integration-with-vision-language-action-pipeline",level:2},{value:"RViz2 for VLA Debugging",id:"rviz2-for-vla-debugging",level:3},{value:"TF2 for VLA Coordination",id:"tf2-for-vla-coordination",level:3},{value:"Practical Examples",id:"practical-examples",level:2},{value:"Example 1: Humanoid Monitoring Dashboard",id:"example-1-humanoid-monitoring-dashboard",level:3},{value:"Example 2: TF2 for Navigation and Manipulation",id:"example-2-tf2-for-navigation-and-manipulation",level:3},{value:"Constitution Alignment",id:"constitution-alignment",level:2},{value:"Visualization Requirements (Key Standard II)",id:"visualization-requirements-key-standard-ii",level:3},{value:"Real-Time Validation (Principle IV)",id:"real-time-validation-principle-iv",level:3},{value:"Anthropomorphic Focus (Principle II)",id:"anthropomorphic-focus-principle-ii",level:3},{value:"Best Practices for Humanoid Robotics",id:"best-practices-for-humanoid-robotics",level:2},{value:"1. TF2 Best Practices",id:"1-tf2-best-practices",level:3},{value:"2. RViz2 Best Practices",id:"2-rviz2-best-practices",level:3},{value:"3. RQt Best Practices",id:"3-rqt-best-practices",level:3},{value:"Exercises",id:"exercises",level:2},{value:"Exercise 1: Custom RViz2 Configuration",id:"exercise-1-custom-rviz2-configuration",level:3},{value:"Exercise 2: RQt Plugin Development",id:"exercise-2-rqt-plugin-development",level:3},{value:"Exercise 3: TF2 Integration",id:"exercise-3-tf2-integration",level:3},{value:"Summary",id:"summary",level:2},{value:"Further Reading",id:"further-reading",level:2}];function c(n){const e={code:"code",h2:"h2",h3:"h3",h4:"h4",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Use RViz2 for robot visualization and debugging"}),"\n",(0,t.jsx)(e.li,{children:"Apply RQt for custom GUI development"}),"\n",(0,t.jsx)(e.li,{children:"Implement TF2 for coordinate frame management"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"introduction",children:"Introduction"}),"\n",(0,t.jsx)(e.p,{children:"ROS 2 provides powerful tools for visualization, debugging, and coordinate management that are essential for developing and operating humanoid robots. RViz2 enables 3D visualization of robot state and sensor data, RQt provides a framework for custom GUI development, and TF2 (Transform Library 2) manages coordinate transformations critical for humanoid perception and action. This chapter explores these essential tools with special attention to their application in humanoid robotics, supporting the Vision-Language-Action pipeline through proper visualization and coordinate management."}),"\n",(0,t.jsx)(e.h2,{id:"rviz2-3d-visualization-for-humanoid-robots",children:"RViz2: 3D Visualization for Humanoid Robots"}),"\n",(0,t.jsx)(e.p,{children:"RViz2 is the 3D visualization tool for ROS 2, crucial for humanoid robot development and debugging."}),"\n",(0,t.jsx)(e.h3,{id:"core-components-of-rviz2",children:"Core Components of RViz2"}),"\n",(0,t.jsx)(e.h4,{id:"displays-panel",children:"Displays Panel"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"RobotModel"}),": Visualizes the robot's URDF model with joint positions"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"TF"}),": Shows coordinate frames and their relationships"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"LaserScan"}),": Visualizes laser range finder data"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Image"}),": Displays camera images"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"PointCloud"}),": Shows 3D point cloud data"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Marker"}),": Custom visualization objects"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Axes"}),": Shows coordinate frame orientations"]}),"\n"]}),"\n",(0,t.jsx)(e.h4,{id:"views-panel",children:"Views Panel"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"FXY (Top-down)"}),": Top-down view of the robot"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Orbit"}),": Free camera that orbits around a target"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Third Person Follower"}),": Camera follows the robot"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"First Person"}),": Camera attached to a robot link"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"setting-up-rviz2-for-humanoid-robots",children:"Setting Up RViz2 for Humanoid Robots"}),"\n",(0,t.jsx)(e.h4,{id:"basic-configuration-file",children:"Basic Configuration File"}),"\n",(0,t.jsxs)(e.p,{children:["Create ",(0,t.jsx)(e.code,{children:"config/humanoid_view.rviz"}),":"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-yaml",children:'Panels:\n  - Class: rviz_common/Displays\n    Help Height: 78\n    Name: Displays\n    Property Tree Widget:\n      Expanded:\n        - /Global Options1\n        - /Status1\n        - /RobotModel1\n        - /TF1\n        - /TF1/Frames1\n        - /Camera1\n        - /PointCloud1\n      Splitter Ratio: 0.5\n    Tree Height: 608\n  - Class: rviz_common/Selection\n    Name: Selection\n  - Class: rviz_common/Tool Properties\n    Expanded:\n      - /2D Goal Pose1\n      - /Publish Point1\n    Name: Tool Properties\n    Splitter Ratio: 0.5886790156364441\n  - Class: rviz_common/Views\n    Expanded:\n      - /Current View1\n    Name: Views\n    Splitter Ratio: 0.5\nVisualization Manager:\n  Class: ""\n  Displays:\n    - Alpha: 0.5\n      Cell Size: 1\n      Class: rviz_default_plugins/Grid\n      Color: 160; 160; 164\n      Enabled: true\n      Line Style:\n        Line Width: 0.029999999329447746\n        Value: Lines\n      Name: Grid\n      Normal Cell Count: 0\n      Offset:\n        X: 0\n        Y: 0\n        Z: 0\n      Plane: XY\n      Plane Cell Count: 10\n      Reference Frame: <Fixed Frame>\n      Value: true\n    - Alpha: 1\n      Class: rviz_default_plugins/RobotModel\n      Collision Enabled: false\n      Description File: ""\n      Description Source: Topic\n      Description Topic:\n        Depth: 5\n        Durability Policy: Volatile\n        History Policy: Keep Last\n        Reliability Policy: Reliable\n        Value: /robot_description\n      Enabled: true\n      Links:\n        All Links Enabled: true\n        Expand Joint Details: false\n        Expand Link Details: false\n        Expand Tree: false\n        Link Tree Style: Links in Alphabetic Order\n      Name: RobotModel\n      TF Prefix: ""\n      Update Interval: 0\n      Value: true\n      Visual Enabled: true\n    - Class: rviz_default_plugins/TF\n      Enabled: true\n      Frame Timeout: 15\n      Frames:\n        All Enabled: true\n      Marker Scale: 0.30000001192092896\n      Name: TF\n      Show Arrows: true\n      Show Axes: true\n      Show Names: false\n      Tree:\n        {}\n      Update Interval: 0\n      Value: true\n    - Class: rviz_default_plugins/Camera\n      Enabled: true\n      Image Topic:\n        Depth: 5\n        Durability Policy: Volatile\n        History Policy: Keep Last\n        Reliability Policy: Reliable\n        Value: /camera/image_raw\n      Name: Camera\n      Overlay Alpha: 0.5\n      Queue Size: 2\n      Transport Hint: raw\n      Value: true\n      Visibility:\n        Grid: true\n        PointCloud: true\n        RobotModel: true\n        TF: true\n        Value: true\n      Zoom Factor: 1\n    - Alpha: 1\n      Autocompute Intensity Bounds: true\n      Autocompute Value Bounds:\n        Max Value: 10\n        Min Value: -10\n        Value: true\n      Axis: Z\n      Channel Name: intensity\n      Class: rviz_default_plugins/PointCloud2\n      Color: 255; 255; 255\n      Color Transformer: RGB8\n      Decay Time: 0\n      Enabled: true\n      Invert Rainbow: false\n      Max Color: 255; 255; 255\n      Max Intensity: 4096\n      Min Color: 0; 0; 0\n      Min Intensity: 0\n      Name: PointCloud\n      Position Transformer: XYZ\n      Queue Size: 10\n      Selectable: true\n      Size (Pixels): 3\n      Size (m): 0.009999999776482582\n      Style: Flat Squares\n      Topic:\n        Depth: 5\n        Durability Policy: Volatile\n        History Policy: Keep Last\n        Reliability Policy: Reliable\n        Value: /camera/depth/points\n      Use Fixed Frame: true\n      Use rainbow: true\n      Value: true\n  Enabled: true\n  Global Options:\n    Background Color: 48; 48; 48\n    Fixed Frame: base_link\n    Frame Rate: 30\n  Name: root\n  Tools:\n    - Class: rviz_default_plugins/Interact\n      Hide Inactive Objects: true\n    - Class: rviz_default_plugins/MoveCamera\n    - Class: rviz_default_plugins/Select\n    - Class: rviz_default_plugins/FocusCamera\n    - Class: rviz_default_plugins/Measure\n      Line color: 128; 128; 0\n    - Class: rviz_default_plugins/SetInitialPose\n      Topic:\n        Depth: 5\n        Durability Policy: Volatile\n        History Policy: Keep Last\n        Reliability Policy: Reliable\n        Value: /initialpose\n    - Class: rviz_default_plugins/SetGoal\n      Topic:\n        Depth: 5\n        Durability Policy: Volatile\n        History Policy: Keep Last\n        Reliability Policy: Reliable\n        Value: /goal_pose\n    - Class: rviz_default_plugins/PublishPoint\n      Single click: true\n      Topic:\n        Depth: 5\n        Durability Policy: Volatile\n        History Policy: Keep Last\n        Reliability Policy: Reliable\n        Value: /clicked_point\n  Transformation:\n    Current:\n      Class: rviz_default_plugins/TF\n  Value: true\n  Views:\n    Current:\n      Class: rviz_default_plugins/Orbit\n      Distance: 2.5\n      Enable Stereo Rendering:\n        Stereo Eye Separation: 0.05999999865889549\n        Stereo Focal Distance: 1\n        Swap Stereo Eyes: false\n        Value: false\n      Focal Point:\n        X: 0\n        Y: 0\n        Z: 0\n      Focal Shape Fixed Size: true\n      Focal Shape Size: 0.05000000074505806\n      Invert Z Axis: false\n      Name: Current View\n      Near Clip Distance: 0.009999999776482582\n      Pitch: 0.5\n      Target Frame: base_link\n      Value: Orbit (rviz)\n      Yaw: 0.5\n    Saved: ~\nWindow Geometry:\n  Camera:\n    collapsed: false\n  Displays:\n    collapsed: false\n  Height: 993\n  Hide Left Dock: false\n  Hide Right Dock: false\n  QMainWindow State: 000000ff00000000fd00000004000000000000015600000363fc0200000008fb0000001200530065006c0065006300740069006f006e00000001e10000009b0000005c00fffffffb0000001e0054006f006f006c002000500072006f007000650072007400690065007302000001ed000001df00000185000000a3fb000000120056006900650077007300200054006f006f02000001df000002110000018500000122fb000000200054006f006f006c002000500072006f0070006500720074006900650073003203000002880000011d000002210000017afb000000100044006900730070006c006100790073010000003d0000029a000000c900fffffffb0000002000730065006c0065006300740069006f006e00200062007500660066006500720200000138000000aa0000023a00000294fb00000014005700690064006500530074006500720065006f02000000e6000000d2000003ee0000030bfb0000000c004b0069006e0065006300740200000186000001060000030c00000261000000010000010f00000363fc0200000003fb0000001e0054006f006f006c002000500072006f00700065007200740069006500730100000041000000780000000000000000fb0000000a00560069006500770073000000003d00000363000000a400fffffffb0000001200530065006c0065006300740069006f006e010000025a000000b200000000000000000000000200000490000000a9fc0100000001fb0000000a00560069006500770073030000004e00000080000002e10000019700000003000004420000003efc0100000002fb0000000800540069006d00650100000000000004420000000000000000fb0000000800540069006d00650100000000000004500000000000000000000004fc0000036300000004000000040000000800000008fc0000000100000002000000010000000a0054006f006f006c00730100000000ffffffff0000000000000000\n  Width: 1853\n  X: 67\n  Y: 27\n'})}),"\n",(0,t.jsx)(e.h3,{id:"rviz2-plugins-for-humanoid-robotics",children:"RViz2 Plugins for Humanoid Robotics"}),"\n",(0,t.jsx)(e.h4,{id:"robotmodel-display",children:"RobotModel Display"}),"\n",(0,t.jsx)(e.p,{children:"Essential for visualizing the humanoid robot's structure:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Description Source"}),': Set to "Topic" and topic to ',(0,t.jsx)(e.code,{children:"/robot_description"})]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Fixed Frame"}),": Set to the robot's base frame (e.g., ",(0,t.jsx)(e.code,{children:"base_link"}),")"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Links"}),": Enable visualization of all robot links with proper colors"]}),"\n"]}),"\n",(0,t.jsx)(e.h4,{id:"tf-display",children:"TF Display"}),"\n",(0,t.jsx)(e.p,{children:"Critical for understanding coordinate frame relationships:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Frames"}),": Enable all robot frames for debugging"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Marker Scale"}),": Adjust to make transforms visible"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Show Names"}),": Enable to identify frames during debugging"]}),"\n"]}),"\n",(0,t.jsx)(e.h4,{id:"camera-display",children:"Camera Display"}),"\n",(0,t.jsx)(e.p,{children:"For vision system debugging:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Image Topic"}),": Set to the camera's image topic (e.g., ",(0,t.jsx)(e.code,{children:"/camera/image_raw"}),")"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Transport Hint"}),": Choose appropriate transport (raw, compressed, etc.)"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Overlay"}),": Enable to overlay camera view on 3D scene"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"launching-rviz2-with-configuration",children:"Launching RViz2 with Configuration"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-xml",children:'\x3c!-- In launch file --\x3e\n<node pkg="rviz2" exec="rviz2" name="rviz2" args="-d $(find-pkg-share my_robot_description)/rviz/humanoid_view.rviz"/>\n'})}),"\n",(0,t.jsx)(e.h2,{id:"rqt-custom-gui-development",children:"RQt: Custom GUI Development"}),"\n",(0,t.jsx)(e.p,{children:"RQt provides a framework for creating custom GUI tools for ROS 2 applications."}),"\n",(0,t.jsx)(e.h3,{id:"core-rqt-concepts",children:"Core RQt Concepts"}),"\n",(0,t.jsx)(e.h4,{id:"plugin-architecture",children:"Plugin Architecture"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"rqt_gui"}),": The main GUI framework"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"rqt_py_common"}),": Common Python utilities for plugins"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"rqt_plot"}),": Plotting tool for data visualization"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"rqt_console"}),": Message logging and filtering"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"rqt_graph"}),": Node graph visualization"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"creating-a-custom-rqt-plugin",children:"Creating a Custom RQt Plugin"}),"\n",(0,t.jsx)(e.h4,{id:"plugin-structure",children:"Plugin Structure"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{children:"my_rqt_package/\n\u251c\u2500\u2500 CMakeLists.txt\n\u251c\u2500\u2500 package.xml\n\u251c\u2500\u2500 setup.py\n\u251c\u2500\u2500 my_rqt_package/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 my_humanoid_control.py\n\u2514\u2500\u2500 resource/\n    \u2514\u2500\u2500 MyHumanoidControl.ui\n"})}),"\n",(0,t.jsx)(e.h4,{id:"plugin-implementation",children:"Plugin Implementation"}),"\n",(0,t.jsxs)(e.p,{children:["Create ",(0,t.jsx)(e.code,{children:"my_rqt_package/my_humanoid_control.py"}),":"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"from python_qt_binding import loadUi\nfrom python_qt_binding.QtWidgets import QWidget, QVBoxLayout, QPushButton, QLabel, QSlider\nfrom python_qt_binding.QtCore import Qt\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import Float64MultiArray\nfrom sensor_msgs.msg import JointState\nfrom builtin_interfaces.msg import Duration\n\nfrom rqt_gui_py.plugin import Plugin\n\nclass MyHumanoidControl(Plugin):\n    def __init__(self, context):\n        super(MyHumanoidControl, self).__init__(context)\n        self.setObjectName('MyHumanoidControl')\n\n        # Create QWidget for the plugin\n        self._widget = QWidget()\n\n        # Initialize ROS node for the plugin\n        rclpy.init(args=None)\n        self.node = Node('rqt_humanoid_control')\n\n        # Create UI elements\n        layout = QVBoxLayout()\n\n        # Joint control section\n        self.joint_label = QLabel('Left Hip Position')\n        layout.addWidget(self.joint_label)\n\n        self.joint_slider = QSlider(Qt.Horizontal)\n        self.joint_slider.setRange(-100, 100)  # -1.0 to 1.0 radians * 100\n        self.joint_slider.setValue(0)\n        self.joint_slider.valueChanged.connect(self.joint_slider_changed)\n        layout.addWidget(self.joint_slider)\n\n        # Status label\n        self.status_label = QLabel('Ready')\n        layout.addWidget(self.status_label)\n\n        # Control buttons\n        self.stand_button = QPushButton('Stand Up')\n        self.stand_button.clicked.connect(self.stand_up)\n        layout.addWidget(self.stand_button)\n\n        self.walk_button = QPushButton('Walk')\n        self.walk_button.clicked.connect(self.walk)\n        layout.addWidget(self.walk_button)\n\n        self._widget.setLayout(layout)\n        context.add_widget(self._widget)\n\n        # Create publishers\n        self.joint_pub = self.node.create_publisher(Float64MultiArray, '/joint_group_position_controller/commands', 10)\n\n        # Timer for updating ROS\n        self.timer = self.node.create_timer(0.1, self.update_ros)\n\n    def joint_slider_changed(self, value):\n        # Convert slider value to radians\n        position = value / 100.0\n        self.status_label.setText(f'Joint position: {position:.2f} rad')\n\n        # Publish joint command\n        msg = Float64MultiArray()\n        msg.data = [position]  # Simplified - real system would have multiple joints\n        self.joint_pub.publish(msg)\n\n    def stand_up(self):\n        self.status_label.setText('Standing up...')\n        # Send stand up command to robot\n\n    def walk(self):\n        self.status_label.setText('Walking...')\n        # Send walk command to robot\n\n    def update_ros(self):\n        # Process ROS callbacks\n        rclpy.spin_once(self.node, timeout_sec=0.01)\n\n    def shutdown_plugin(self):\n        # Clean up resources\n        self.timer.destroy()\n        self.node.destroy_node()\n        rclpy.shutdown()\n\n    def save_settings(self, plugin_settings, instance_settings):\n        # Save plugin settings\n        pass\n\n    def restore_settings(self, plugin_settings, instance_settings):\n        # Restore plugin settings\n        pass\n"})}),"\n",(0,t.jsx)(e.h4,{id:"plugin-configuration",children:"Plugin Configuration"}),"\n",(0,t.jsxs)(e.p,{children:["Create ",(0,t.jsx)(e.code,{children:"plugin.xml"}),":"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-xml",children:'<library path="my_rqt_package">\n  <class name="My Humanoid Control" type="my_rqt_package.my_humanoid_control.MyHumanoidControl" base_class_type="rqt_gui_py::Plugin">\n    <description>\n      Custom control panel for humanoid robot\n    </description>\n    <qtgui>\n      <group>\n        <label>Robot Tools</label>\n        <icon type="theme">folder</icon>\n        <statustip>Robot tools</statustip>\n      </group>\n      <label>My Humanoid Control</label>\n      <icon type="theme">input-gaming</icon>\n      <statustip>Custom control panel for humanoid robot</statustip>\n    </qtgui>\n  </class>\n</library>\n'})}),"\n",(0,t.jsx)(e.h4,{id:"package-configuration",children:"Package Configuration"}),"\n",(0,t.jsxs)(e.p,{children:["Update ",(0,t.jsx)(e.code,{children:"setup.py"})," to include the plugin:"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"from setuptools import setup\n\npackage_name = 'my_rqt_package'\n\nsetup(\n    name=package_name,\n    version='0.0.0',\n    packages=[package_name],\n    package_dir={'': 'src'},\n    data_files=[\n        ('share/ament_index/resource_index/packages',\n            ['resource/' + package_name]),\n        ('share/' + package_name, ['package.xml']),\n        ('share/' + package_name + '/resource',\n            ['resource/MyHumanoidControl.ui']),\n        ('lib/' + package_name, ['scripts/my_humanoid_control']),\n        ('share/' + package_name, ['plugin.xml']),\n    ],\n    install_requires=['setuptools'],\n    zip_safe=True,\n    author='Your Name',\n    maintainer='Your Name',\n    maintainer_email='your.email@example.com',\n    keywords=['ROS'],\n    entry_points={\n        'console_scripts': [\n        ],\n    },\n)\n"})}),"\n",(0,t.jsx)(e.h2,{id:"tf2-transform-library-for-coordinate-management",children:"TF2: Transform Library for Coordinate Management"}),"\n",(0,t.jsx)(e.p,{children:"TF2 (Transform Library 2) is critical for humanoid robots that must manage multiple coordinate frames for vision, navigation, and manipulation."}),"\n",(0,t.jsx)(e.h3,{id:"tf2-core-concepts",children:"TF2 Core Concepts"}),"\n",(0,t.jsx)(e.h4,{id:"coordinate-frames",children:"Coordinate Frames"}),"\n",(0,t.jsx)(e.p,{children:"For humanoid robots, common frames include:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"base_link"}),": Robot's main body frame"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"odom"}),": Odometry frame for navigation"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"map"}),": Global map frame"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"camera_link"}),": Camera frame for vision"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"left_hand"}),": End-effector frame for manipulation"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"imu_link"}),": IMU frame for balance feedback"]}),"\n"]}),"\n",(0,t.jsx)(e.h4,{id:"transform-messages",children:"Transform Messages"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"tf2_msgs/TFMessage"}),": Contains multiple transforms"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"geometry_msgs/TransformStamped"}),": Single transform with timestamp"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"tf2-in-python",children:"TF2 in Python"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom tf2_ros import TransformBroadcaster, TransformListener, Buffer\nfrom geometry_msgs.msg import TransformStamped, PointStamped\nfrom tf2_geometry_msgs import do_transform_point\nimport tf2_ros\n\nclass TF2DemoNode(Node):\n    def __init__(self):\n        super().__init__('tf2_demo_node')\n\n        # Create transform broadcaster\n        self.tf_broadcaster = TransformBroadcaster(self)\n\n        # Create transform buffer and listener\n        self.tf_buffer = Buffer()\n        self.tf_listener = TransformListener(self.tf_buffer, self)\n\n        # Timer to broadcast transforms\n        self.timer = self.create_timer(0.1, self.broadcast_transforms)\n\n        # Timer to lookup transforms\n        self.lookup_timer = self.create_timer(1.0, self.lookup_transforms)\n\n    def broadcast_transforms(self):\n        \"\"\"Broadcast robot transforms\"\"\"\n        t = TransformStamped()\n\n        # Header\n        t.header.stamp = self.get_clock().now().to_msg()\n        t.header.frame_id = 'odom'\n        t.child_frame_id = 'base_link'\n\n        # Transform (simplified - moving in x direction)\n        t.transform.translation.x = 1.0  # This would come from odometry\n        t.transform.translation.y = 0.0\n        t.transform.translation.z = 0.0\n        t.transform.rotation.x = 0.0\n        t.transform.rotation.y = 0.0\n        t.transform.rotation.z = 0.0\n        t.transform.rotation.w = 1.0\n\n        self.tf_broadcaster.sendTransform(t)\n\n    def lookup_transforms(self):\n        \"\"\"Lookup and use transforms\"\"\"\n        try:\n            # Lookup transform from base_link to camera_link\n            trans = self.tf_buffer.lookup_transform(\n                'odom',\n                'base_link',\n                rclpy.time.Time())  # Use 0 for latest available\n\n            self.get_logger().info(\n                f'Robot position: x={trans.transform.translation.x:.2f}, '\n                f'y={trans.transform.translation.y:.2f}'\n            )\n\n        except tf2_ros.TransformException as ex:\n            self.get_logger().error(f'Could not transform: {ex}')\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = TF2DemoNode()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,t.jsx)(e.h3,{id:"tf2-for-humanoid-robot-applications",children:"TF2 for Humanoid Robot Applications"}),"\n",(0,t.jsx)(e.h4,{id:"vision-integration",children:"Vision Integration"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"def transform_point_to_robot_frame(self, camera_point):\n    \"\"\"Transform a point from camera frame to robot base frame\"\"\"\n    point_camera = PointStamped()\n    point_camera.header.frame_id = 'camera_link'\n    point_camera.header.stamp = self.get_clock().now().to_msg()\n    point_camera.point.x = camera_point[0]\n    point_camera.point.y = camera_point[1]\n    point_camera.point.z = camera_point[2]\n\n    try:\n        # Transform to base frame\n        point_base = self.tf_buffer.transform(\n            point_camera,\n            'base_link',\n            timeout=rclpy.duration.Duration(seconds=1.0)\n        )\n        return [point_base.point.x, point_base.point.y, point_base.point.z]\n    except tf2_ros.TransformException as e:\n        self.get_logger().error(f'Transform failed: {e}')\n        return None\n"})}),"\n",(0,t.jsx)(e.h4,{id:"manipulation-planning",children:"Manipulation Planning"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'def get_end_effector_pose(self, end_effector_frame):\n    """Get the pose of an end effector in base frame"""\n    try:\n        transform = self.tf_buffer.lookup_transform(\n            \'base_link\',\n            end_effector_frame,\n            rclpy.time.Time(),\n            timeout=rclpy.duration.Duration(seconds=1.0)\n        )\n        return transform\n    except tf2_ros.TransformException as e:\n        self.get_logger().error(f\'Could not get end effector pose: {e}\')\n        return None\n'})}),"\n",(0,t.jsx)(e.h2,{id:"integration-with-vision-language-action-pipeline",children:"Integration with Vision-Language-Action Pipeline"}),"\n",(0,t.jsx)(e.h3,{id:"rviz2-for-vla-debugging",children:"RViz2 for VLA Debugging"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Vision"}),": Camera feeds and point clouds for perception debugging"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Language"}),": Display recognized objects and commands"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Action"}),": Robot trajectory visualization and execution monitoring"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"tf2-for-vla-coordination",children:"TF2 for VLA Coordination"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Vision-Action"}),": Transform detected objects to manipulation frame"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Language-Action"}),": Transform navigation goals from map to robot frame"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Multi-frame"}),": Coordinate between vision, planning, and execution frames"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"practical-examples",children:"Practical Examples"}),"\n",(0,t.jsx)(e.h3,{id:"example-1-humanoid-monitoring-dashboard",children:"Example 1: Humanoid Monitoring Dashboard"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"import sys\nfrom PyQt5.QtWidgets import QApplication, QMainWindow, QVBoxLayout, QWidget, QLabel, QProgressBar\nfrom PyQt5.QtCore import QTimer\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import JointState\nfrom std_msgs.msg import Float64MultiArray\n\nclass HumanoidMonitor(Node):\n    def __init__(self):\n        super().__init__('humanoid_monitor')\n\n        # Subscriptions\n        self.joint_sub = self.create_subscription(\n            JointState,\n            '/joint_states',\n            self.joint_callback,\n            10\n        )\n\n        self.status_sub = self.create_subscription(\n            Float64MultiArray,\n            '/balance_status',\n            self.balance_callback,\n            10\n        )\n\n        # Data storage\n        self.joint_positions = {}\n        self.balance_stable = True\n\n    def joint_callback(self, msg):\n        for i, name in enumerate(msg.name):\n            if i < len(msg.position):\n                self.joint_positions[name] = msg.position[i]\n\n    def balance_callback(self, msg):\n        # Balance status: 0=unstable, 1=stable\n        if len(msg.data) > 0:\n            self.balance_stable = msg.data[0] > 0.5\n\nclass MonitorWindow(QMainWindow):\n    def __init__(self, ros_node):\n        super().__init__()\n        self.ros_node = ros_node\n        self.initUI()\n\n        # Timer to update UI\n        self.timer = QTimer()\n        self.timer.timeout.connect(self.update_ui)\n        self.timer.start(100)  # Update every 100ms\n\n    def initUI(self):\n        self.setWindowTitle('Humanoid Robot Monitor')\n        self.setGeometry(100, 100, 400, 300)\n\n        central_widget = QWidget()\n        self.setCentralWidget(central_widget)\n\n        layout = QVBoxLayout()\n\n        # Balance status\n        self.balance_label = QLabel('Balance Status: Stable')\n        layout.addWidget(self.balance_label)\n\n        # Joint count\n        self.joint_count_label = QLabel('Joints: 0')\n        layout.addWidget(self.joint_count_label)\n\n        # Battery level (simulated)\n        self.battery_label = QLabel('Battery: 100%')\n        self.battery_bar = QProgressBar()\n        self.battery_bar.setRange(0, 100)\n        self.battery_bar.setValue(100)\n        layout.addWidget(self.battery_label)\n        layout.addWidget(self.battery_bar)\n\n        central_widget.setLayout(layout)\n\n    def update_ui(self):\n        # Update balance status\n        status = \"Stable\" if self.ros_node.balance_stable else \"Unstable\"\n        self.balance_label.setText(f'Balance Status: {status}')\n\n        # Update joint count\n        joint_count = len(self.ros_node.joint_positions)\n        self.joint_count_label.setText(f'Joints: {joint_count}')\n\n        # Process ROS callbacks\n        rclpy.spin_once(self.ros_node, timeout_sec=0.01)\n\ndef main():\n    rclpy.init()\n\n    # Create ROS node\n    monitor_node = HumanoidMonitor()\n\n    # Create Qt application\n    app = QApplication(sys.argv)\n    window = MonitorWindow(monitor_node)\n    window.show()\n\n    try:\n        sys.exit(app.exec_())\n    except KeyboardInterrupt:\n        pass\n    finally:\n        monitor_node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,t.jsx)(e.h3,{id:"example-2-tf2-for-navigation-and-manipulation",children:"Example 2: TF2 for Navigation and Manipulation"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import PoseStamped, PointStamped\nfrom tf2_ros import Buffer, TransformListener\nfrom tf2_geometry_msgs import do_transform_point\nimport tf2_ros\n\nclass NavigationPlanner(Node):\n    def __init__(self):\n        super().__init__('navigation_planner')\n\n        # TF buffer and listener\n        self.tf_buffer = Buffer()\n        self.tf_listener = TransformListener(self.tf_buffer, self)\n\n        # Publishers for navigation\n        self.nav_goal_pub = self.create_publisher(PoseStamped, '/goal_pose', 10)\n\n        # Timer for demonstration\n        self.timer = self.create_timer(5.0, self.plan_navigation)\n\n    def plan_navigation(self):\n        \"\"\"Plan navigation to a point in camera frame\"\"\"\n        # Assume we detected an object in camera frame\n        target_in_camera = PointStamped()\n        target_in_camera.header.frame_id = 'camera_link'\n        target_in_camera.header.stamp = self.get_clock().now().to_msg()\n        target_in_camera.point.x = 1.0  # 1m in front of camera\n        target_in_camera.point.y = 0.0\n        target_in_camera.point.z = 0.0\n\n        try:\n            # Transform to map frame for navigation\n            target_in_map = self.tf_buffer.transform(\n                target_in_camera,\n                'map',\n                timeout=rclpy.duration.Duration(seconds=1.0)\n            )\n\n            # Create navigation goal\n            goal = PoseStamped()\n            goal.header.frame_id = 'map'\n            goal.header.stamp = self.get_clock().now().to_msg()\n            goal.pose.position = target_in_map.point\n            goal.pose.orientation.w = 1.0  # No rotation\n\n            self.nav_goal_pub.publish(goal)\n            self.get_logger().info(f'Navigating to: x={goal.pose.position.x:.2f}, y={goal.pose.position.y:.2f}')\n\n        except tf2_ros.TransformException as e:\n            self.get_logger().error(f'Transform error: {e}')\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = NavigationPlanner()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,t.jsx)(e.h2,{id:"constitution-alignment",children:"Constitution Alignment"}),"\n",(0,t.jsx)(e.p,{children:"This chapter addresses several constitutional requirements:"}),"\n",(0,t.jsx)(e.h3,{id:"visualization-requirements-key-standard-ii",children:"Visualization Requirements (Key Standard II)"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Proper use of Docusaurus Admonitions in documentation"}),"\n",(0,t.jsx)(e.li,{children:"Mermaid diagrams for illustrating TF frame relationships"}),"\n",(0,t.jsx)(e.li,{children:"Clear examples for complex concepts"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"real-time-validation-principle-iv",children:"Real-Time Validation (Principle IV)"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Efficient TF lookups for real-time applications"}),"\n",(0,t.jsx)(e.li,{children:"Proper QoS profiles for visualization data"}),"\n",(0,t.jsx)(e.li,{children:"Performance considerations for GUI applications"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"anthropomorphic-focus-principle-ii",children:"Anthropomorphic Focus (Principle II)"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Humanoid-specific coordinate frame management"}),"\n",(0,t.jsx)(e.li,{children:"Integration with bipedal locomotion systems"}),"\n",(0,t.jsx)(e.li,{children:"Manipulation frame considerations"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"best-practices-for-humanoid-robotics",children:"Best Practices for Humanoid Robotics"}),"\n",(0,t.jsx)(e.h3,{id:"1-tf2-best-practices",children:"1. TF2 Best Practices"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Use appropriate frame naming conventions"}),"\n",(0,t.jsx)(e.li,{children:"Set proper timeouts for transform lookups"}),"\n",(0,t.jsx)(e.li,{children:"Handle transform exceptions gracefully"}),"\n",(0,t.jsx)(e.li,{children:"Use static transforms for fixed relationships"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"2-rviz2-best-practices",children:"2. RViz2 Best Practices"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Create configuration files for common views"}),"\n",(0,t.jsx)(e.li,{children:"Use appropriate QoS profiles for visualization topics"}),"\n",(0,t.jsx)(e.li,{children:"Optimize visualization performance for real-time use"}),"\n",(0,t.jsx)(e.li,{children:"Include relevant displays for humanoid debugging"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"3-rqt-best-practices",children:"3. RQt Best Practices"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Design intuitive interfaces for robot operators"}),"\n",(0,t.jsx)(e.li,{children:"Include safety features and validation"}),"\n",(0,t.jsx)(e.li,{children:"Use appropriate data types for real-time performance"}),"\n",(0,t.jsx)(e.li,{children:"Implement proper error handling"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"exercises",children:"Exercises"}),"\n",(0,t.jsx)(e.h3,{id:"exercise-1-custom-rviz2-configuration",children:"Exercise 1: Custom RViz2 Configuration"}),"\n",(0,t.jsx)(e.p,{children:"Create a custom RViz2 configuration file for a humanoid robot that includes:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Robot model display with proper URDF"}),"\n",(0,t.jsx)(e.li,{children:"TF tree visualization showing all relevant frames"}),"\n",(0,t.jsx)(e.li,{children:"Camera feed for vision system monitoring"}),"\n",(0,t.jsx)(e.li,{children:"Point cloud display for 3D perception"}),"\n",(0,t.jsx)(e.li,{children:"Appropriate fixed frame and view settings"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"exercise-2-rqt-plugin-development",children:"Exercise 2: RQt Plugin Development"}),"\n",(0,t.jsx)(e.p,{children:"Develop a custom RQt plugin for humanoid robot control that includes:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Joint position sliders for key joints"}),"\n",(0,t.jsx)(e.li,{children:"Balance status indicator"}),"\n",(0,t.jsx)(e.li,{children:"Emergency stop button"}),"\n",(0,t.jsx)(e.li,{children:"Walking gait controls"}),"\n",(0,t.jsx)(e.li,{children:"Proper error handling and safety features"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"exercise-3-tf2-integration",children:"Exercise 3: TF2 Integration"}),"\n",(0,t.jsx)(e.p,{children:"Implement TF2 functionality for a humanoid robot that:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Manages coordinate frames for vision, navigation, and manipulation"}),"\n",(0,t.jsx)(e.li,{children:"Transforms points between camera and base frames"}),"\n",(0,t.jsx)(e.li,{children:"Handles exceptions and timeouts appropriately"}),"\n",(0,t.jsx)(e.li,{children:"Integrates with the VLA pipeline for object manipulation"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsx)(e.p,{children:"RViz2, RQt, and TF2 are essential tools for humanoid robot development, providing visualization, custom interfaces, and coordinate management capabilities. These tools enable effective debugging and operation of complex humanoid systems, supporting the Vision-Language-Action pipeline through proper visualization and coordinate transformation. Understanding these tools is crucial for developing and operating humanoid robots that can function effectively in human-centered environments."}),"\n",(0,t.jsx)(e.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:'"Programming Robots with ROS" by Quigley et al. (Visualization chapter)'}),"\n",(0,t.jsx)(e.li,{children:'"Mastering ROS for Robotics Programming" by Jayanam (RViz and TF chapters)'}),"\n",(0,t.jsx)(e.li,{children:'"ROS Robot Programming" by Kim et al.'}),"\n",(0,t.jsx)(e.li,{children:'"TF2 tutorials" - ROS Wiki'}),"\n",(0,t.jsx)(e.li,{children:'"RQt tutorials" - ROS Wiki'}),"\n"]})]})}function u(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(c,{...n})}):c(n)}},8453(n,e,i){i.d(e,{R:()=>r,x:()=>s});var o=i(6540);const t={},a=o.createContext(t);function r(n){const e=o.useContext(a);return o.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:r(n.components),o.createElement(a.Provider,{value:e},n.children)}}}]);